{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "## Classification Using SVM\n",
    "Load dataset. We will re-use the CERN dataset from project 1, available from https://inclass.kaggle.com/c/epfml-project-1/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,) (5000, 30)\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_csv_data\n",
    "\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "\n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cost and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_primal_objective(y, X, w, lambda_):\n",
    "    \"\"\"compute the full cost (the primal objective), that is loss plus regularizer.\n",
    "    X: the full dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    return (lambda_ / 2) * w @ w.T + np.sum(np.vstack((np.zeros(y.shape), (1 - y * (X @ w)))).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y, X, w):\n",
    "    \"\"\"compute the training accuracy on the training set (can be called for test set as well).\n",
    "    X: the full dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    y_train = X @ w\n",
    "    y_train[y_train > 0] = 1\n",
    "    y_train[y_train < 0] = -1\n",
    "    return np.sum(y_train == y) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the (stochastic) subgradient for the n-th summand of the SVM optimization objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stochastic_gradient(y, X, w, lambda_, n, num_examples):\n",
    "    \"\"\"compute the stochastic gradient of loss plus regularizer.\n",
    "    X: the dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    n: the index of the (one) datapoint we have sampled\n",
    "    num_examples: N\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    # Be careful about the constant N (size) term!\n",
    "    # The complete objective for SVM is a sum, not an average as in earlier SGD examples!\n",
    "    x_n, y_n = X[n], y[n]\n",
    "    hinge = max(0, (1 - y_n * (x_n @ w)))\n",
    "    if hinge == 0:\n",
    "        return num_examples * lambda_ * w\n",
    "    else:\n",
    "        return num_examples * (-y_n) * x_n  + lambda_ * w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement stochastic gradient descent: Pick a data point uniformly at random and update w based on the gradient for the n-th summand of the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.635050e+05  3.304600e+05  5.253700e+05  2.052950e+05  7.555000e+03\n",
      "  8.210100e+05  3.670000e+03  1.141500e+04  2.347000e+04  1.074925e+06\n",
      "  6.230000e+03 -7.025000e+03  5.000000e+00  1.937250e+05 -4.540000e+03\n",
      "  1.404500e+04  2.413600e+05  4.490000e+03  7.060000e+03  1.331500e+05\n",
      " -4.665000e+03  1.747550e+06  1.000000e+04  3.254300e+05 -1.935000e+03\n",
      " -1.280000e+04  3.144050e+05 -9.485000e+03 -2.400000e+02  6.398350e+05]\n",
      "iteration=0, cost=3567186280319.23\n",
      "[ 2.29239861e+04 -2.22985220e+04 -1.29858742e+04  1.74786109e+04\n",
      " -1.68714162e+04 -1.18044282e+04 -1.69143430e+04 -3.38937267e+02\n",
      "  3.41080319e+02  1.86998951e+03 -6.38403055e+02  7.14279187e+02\n",
      " -1.65500567e+04  8.13461542e+03 -8.01270108e+00  5.51122617e+01\n",
      " -5.39536309e+03  3.02620141e+02  5.23701304e+01  7.75025505e+03\n",
      " -1.15658020e+02 -1.67158473e+04 -5.72761007e+02  3.09412773e+04\n",
      "  2.23406103e+04  2.15070279e+04 -2.28017614e+04 -1.64734587e+04\n",
      " -1.67492284e+04 -8.69253065e+02]\n",
      "iteration=10000, cost=3420872832.6255593\n",
      "[ 4.39482614e+04 -3.60084115e+04 -1.94639484e+04  1.23488414e+04\n",
      "  4.86134006e+03  1.41542899e+04  4.11401651e+03 -4.76546651e+02\n",
      " -1.98215145e+03 -4.43373055e+03 -7.54185660e+02  5.99183445e+02\n",
      "  4.93819903e+03  1.11071032e+04 -1.44454692e+01 -8.95853791e+01\n",
      " -8.84247349e+03  8.53347063e+01  1.19034197e+02 -9.77675164e+03\n",
      "  6.45272156e+01 -1.84904930e+04 -3.53453537e+02  2.04587776e+04\n",
      "  2.04550253e+04  2.05295437e+04  3.95953772e+02  4.70543015e+03\n",
      "  4.72983315e+03 -6.69827486e+03]\n",
      "iteration=20000, cost=1377115340.20565\n",
      "[ 34858.91375457 -27623.75184136 -19642.38764441  17557.60414879\n",
      "   1659.51081664  12459.49083943   1361.90117518   -367.09362373\n",
      "  -2505.05729028  -1676.54608598   -484.98117283    512.33224993\n",
      "   1814.19669537   6833.69620156    234.41571375     51.98814316\n",
      "  -5136.08626774    245.25531333   -156.68830185   3770.95328464\n",
      "    -84.72334671  -4520.69480338   -419.97630902  10898.13985631\n",
      "   6263.38187533   6241.75469917  -1633.50922482   1956.97424358\n",
      "   1931.85559195  -3374.04070789]\n",
      "iteration=30000, cost=668579836.4347318\n",
      "[ 2.49701179e+04 -2.16956209e+04 -9.88481262e+03  6.30993840e+03\n",
      "  1.26567369e+03 -6.07822159e+02  1.44594759e+03 -3.85141558e+01\n",
      " -2.94561404e+03  2.55630858e+03 -4.82228707e+02  4.24607704e+02\n",
      "  1.42595641e+03  1.03791065e+04 -1.22197384e+02 -1.10840644e+00\n",
      " -3.74868799e+03  1.01276574e+02  5.03461098e+01 -4.10414948e+02\n",
      "  1.02339197e+02 -1.04284461e+04 -1.45593186e+02  1.26349632e+04\n",
      "  1.07558363e+04  1.07488886e+04 -1.15905422e+03  1.49566080e+03\n",
      "  1.49548887e+03 -4.07413569e+03]\n",
      "iteration=40000, cost=438659690.42130536\n",
      "[ 7.26323716e+05  5.26685550e+05  5.49492356e+05  3.05624904e+03\n",
      " -4.99500078e+06 -4.99499912e+06 -4.99500082e+06  1.38449725e+04\n",
      "  3.05463170e+03  5.55455193e+05  9.07489421e+03 -6.77990623e+03\n",
      " -4.99500076e+06  1.97307473e+05  5.23504821e+03 -1.15800518e+04\n",
      "  3.58149325e+05  1.84504897e+03  6.41006491e+03  2.03240022e+05\n",
      " -7.10504536e+03  2.80033812e+05 -3.48153919e-02 -4.99499863e+06\n",
      " -4.99499883e+06 -4.99499880e+06 -4.99500159e+06 -4.99500076e+06\n",
      " -4.99500076e+06 -1.60442463e+00]\n",
      "iteration=50000, cost=579293367.934237\n",
      "[ 25601.21782597 -21734.70429376 -10217.4322468    5105.42055436\n",
      "   1577.07684864   4199.02150839   1382.61469912    -96.09643141\n",
      "  -4464.97012089     98.28873024   -562.68558938    454.71117569\n",
      "   1628.94705858  10657.21795089    134.76877242     47.00369206\n",
      "  -3966.9003458      62.56911026    185.9165913   -1431.6713086\n",
      "    110.71214044  -3514.60842896   -203.09499172   2709.14615671\n",
      "    710.91603729    682.47427118  -3144.60507701   1621.75673008\n",
      "   1571.22947881  -6591.99643546]\n",
      "iteration=60000, cost=239690275.7789137\n",
      "[  6109.86142116 -22624.73841248  -8503.30845314   3221.37103661\n",
      "    822.80202643   4071.95036573    773.44748015    -31.20913736\n",
      "  -3428.72841473   1166.72585755   -510.52189652    380.43898828\n",
      "    884.12069123  10869.44150093     94.87806816    -49.48763758\n",
      "  -4652.47744484     72.16411919     86.72977992  -3101.16059839\n",
      "    -28.33928962  -4966.9032491    -145.67666922   8096.64073199\n",
      "   5422.49862354   5525.69878265  -2173.66219457    984.51333945\n",
      "    928.54100671  -5050.10137583]\n",
      "iteration=70000, cost=330232055.62531674\n",
      "[ 7.20397376e+03 -2.28379134e+04 -8.15362438e+03  6.23485968e+03\n",
      "  1.99402570e+03  3.74227327e+03  1.75790110e+03 -9.62544235e+01\n",
      " -1.11223585e+01  1.49494143e+03 -5.36451992e+02  3.99678572e+02\n",
      "  2.07647532e+03  9.21180566e+03  2.24983910e+02 -1.28102693e+02\n",
      " -4.44559866e+03  3.44656938e+02  1.70798753e+01 -1.54480758e+03\n",
      "  4.93209279e+01 -1.37115687e+03 -2.28042292e+02  8.76483766e+03\n",
      "  3.11506138e+03  2.97300819e+03 -2.79626209e+03  2.03933083e+03\n",
      "  2.03248781e+03 -3.27114845e+03]\n",
      "iteration=80000, cost=368440084.5450563\n",
      "[ 1.47341659e+04 -1.84822176e+04 -1.04590625e+04  4.14926101e+03\n",
      "  7.24062815e+02  6.53983579e+03  4.94958323e+02  5.91286699e+01\n",
      " -6.46658521e+02  8.33850789e+02 -3.40791184e+02  5.00709351e+02\n",
      "  7.42002353e+02  7.62385028e+03  1.33849548e+02 -3.24728650e+01\n",
      " -1.86048097e+03  1.88385196e+02 -1.72466044e+00 -2.62294537e+03\n",
      "  1.61306834e+02 -1.29315617e+03 -8.30720116e+01  5.88801587e+03\n",
      "  4.76731693e+03  4.92363206e+03 -1.17876861e+03  6.53559490e+02\n",
      "  6.35261123e+02 -4.92947973e+03]\n",
      "iteration=90000, cost=341299761.3818794\n",
      "training accuracy = 0.7092\n"
     ]
    }
   ],
   "source": [
    "def sgd_for_svm_demo(y, X):\n",
    "    \n",
    "    max_iter = 100000\n",
    "    gamma = 1\n",
    "    lambda_ = 0.01\n",
    "    \n",
    "    num_examples, num_features = X.shape\n",
    "    w = np.zeros(num_features)\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        # n = sample one data point uniformly at random data from x\n",
    "        n = random.randint(0,num_examples-1)\n",
    "        \n",
    "        grad = calculate_stochastic_gradient(y, X, w, lambda_, n, num_examples)\n",
    "        w -= gamma/(it+1) * grad\n",
    "        if it % 10000 == 0:\n",
    "            print(grad)\n",
    "            cost = calculate_primal_objective(y, X, w, lambda_)\n",
    "            print(\"iteration={i}, cost={c}\".format(i=it, c=cost))\n",
    "    \n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, X, w)))\n",
    "\n",
    "sgd_for_svm_demo(y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Descent (Ascent) for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the closed-form update for the n-th variable alpha, in the dual optimization problem, given alpha and the current corresponding w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coordinate_update(y, X, lambda_, alpha, w, n):\n",
    "    \"\"\"compute a coordinate update (closed form) for coordinate n.\n",
    "    X: the dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    n: the coordinate to be updated\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    # calculate the update of coordinate at index=n.\n",
    "    x_n, y_n = X[n], y[n]\n",
    "    old_alpha_n = np.copy(alpha[n])\n",
    "    hinge = 1 - y_n * x_n @ w\n",
    "    new_alpha = old_alpha_n + (lambda_ / (x_n @ x_n))*(1 - y_n * (x_n @ w))\n",
    "    if new_alpha < 0:\n",
    "        new_alpha = 0\n",
    "    elif new_alpha > 1:\n",
    "        new_alpha = 1\n",
    "    #Compute optimal new alpha\n",
    "    #if old_alpha_n == 0:\n",
    "    #    new_alpha = 0\n",
    "    #elif hinge > 0:\n",
    "    #    new_alpha = 1\n",
    "    #else:\n",
    "    #    new_alpha = 0.5\n",
    "    #alpha[n] = new_alpha\n",
    "    #Compute new w\n",
    "    w += (1 / lambda_) * x_n * y_n * new_alpha\n",
    "    return w, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.arange(16).reshape(4,4)\n",
    "display(M)\n",
    "m_n = M[2]\n",
    "m_n.T @ m_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dual_objective(y, X, w, alpha, lambda_):\n",
    "    \"\"\"calculate the objective for the dual problem.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    y_diag = np.diag(y)\n",
    "    Q = y_diag @ X @ X.T @ y_diag\n",
    "    return np.sum(alpha) - (1 / (2 * lambda_)) * alpha.T @ Q @ alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698402922674.1354 -356843916.43185\n",
      "iteration=0, primal:698402922674.13538, dual:-356843916.43185, gap:698759766590.56726\n",
      "211594843556.60797 -195583591.46979952\n",
      "iteration=10, primal:211594843556.60797, dual:-195583591.46980, gap:211790427148.07776\n",
      "97473037057.7303 -53237793.500350095\n",
      "iteration=20, primal:97473037057.73030, dual:-53237793.50035, gap:97526274851.23065\n",
      "215270093139.3534 -165348172.4336997\n",
      "iteration=30, primal:215270093139.35339, dual:-165348172.43370, gap:215435441311.78708\n",
      "355717663481.4634 -320205341.6599002\n",
      "iteration=40, primal:355717663481.46338, dual:-320205341.65990, gap:356037868823.12329\n",
      "995497349856.6698 -496144312.97925097\n",
      "iteration=50, primal:995497349856.66980, dual:-496144312.97925, gap:995993494169.64905\n",
      "619649781971.2169 -951877856.2197013\n",
      "iteration=60, primal:619649781971.21692, dual:-951877856.21970, gap:620601659827.43665\n",
      "513592169240.9718 -1463623750.03245\n",
      "iteration=70, primal:513592169240.97180, dual:-1463623750.03245, gap:515055792991.00427\n",
      "513592169240.9718 -1463623750.03245\n",
      "iteration=80, primal:513592169240.97180, dual:-1463623750.03245, gap:515055792991.00427\n",
      "607659973364.548 -942618550.5454018\n",
      "iteration=90, primal:607659973364.54797, dual:-942618550.54540, gap:608602591915.09338\n",
      "647901064864.0693 -957509830.0478532\n",
      "iteration=100, primal:647901064864.06934, dual:-957509830.04785, gap:648858574694.11719\n",
      "384901571509.99646 -713805453.3849497\n",
      "iteration=110, primal:384901571509.99646, dual:-713805453.38495, gap:385615376963.38141\n",
      "610866345951.2045 -946749355.6481016\n",
      "iteration=120, primal:610866345951.20447, dual:-946749355.64810, gap:611813095306.85254\n",
      "271285218974.57333 -260684752.41664857\n",
      "iteration=130, primal:271285218974.57333, dual:-260684752.41665, gap:271545903726.98999\n",
      "267033796346.1837 -290627391.8438489\n",
      "iteration=140, primal:267033796346.18369, dual:-290627391.84385, gap:267324423738.02753\n",
      "1376175082498.685 -565969123.6664479\n",
      "iteration=150, primal:1376175082498.68506, dual:-565969123.66645, gap:1376741051622.35156\n",
      "228335357425.64874 -392200754.53644717\n",
      "iteration=160, primal:228335357425.64874, dual:-392200754.53645, gap:228727558180.18518\n",
      "349907887631.764 -827802374.7725451\n",
      "iteration=170, primal:349907887631.76398, dual:-827802374.77255, gap:350735690006.53650\n",
      "1130716812154.4385 -891734786.817297\n",
      "iteration=180, primal:1130716812154.43848, dual:-891734786.81730, gap:1131608546941.25586\n",
      "193637779763.68347 -361682581.2972412\n",
      "iteration=190, primal:193637779763.68347, dual:-361682581.29724, gap:193999462344.98071\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-20cdf114f474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training accuracy = {l}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcoordinate_descent_for_svm_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-20cdf114f474>\u001b[0m in \u001b[0;36mcoordinate_descent_for_svm_demo\u001b[0;34m(y, X)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprimal_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_primal_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# dual objective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mdual_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dual_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m# primal dual gap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mduality_gap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimal_value\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdual_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-7e83d3b42278>\u001b[0m in \u001b[0;36mcalculate_dual_objective\u001b[0;34m(y, X, w, alpha, lambda_)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# ***************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_diag\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my_diag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def coordinate_descent_for_svm_demo(y, X):\n",
    "    max_iter = 10000\n",
    "    lambda_ = 0.01\n",
    "\n",
    "    num_examples, num_features = X.shape\n",
    "    w = np.zeros(num_features)\n",
    "    alpha = np.zeros(num_examples)\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        # n = sample one data point uniformly at random data from x\n",
    "        n = random.randint(0,num_examples-1)\n",
    "        \n",
    "        w, alpha = calculate_coordinate_update(y, X, lambda_, alpha, w, n)\n",
    "        if it % 10 == 0:\n",
    "            # primal objective\n",
    "            primal_value = calculate_primal_objective(y, X, w, lambda_)\n",
    "            # dual objective\n",
    "            dual_value = calculate_dual_objective(y, X, w, alpha, lambda_)\n",
    "            # primal dual gap\n",
    "            duality_gap = primal_value - dual_value\n",
    "            print(primal_value, dual_value)\n",
    "            print('iteration=%i, primal:%.5f, dual:%.5f, gap:%.5f'%(\n",
    "                    it, primal_value, dual_value, duality_gap))\n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, X, w)))\n",
    "\n",
    "coordinate_descent_for_svm_demo(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
